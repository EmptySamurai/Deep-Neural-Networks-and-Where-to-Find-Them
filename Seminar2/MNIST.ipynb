{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist \n",
    "from keras import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000, 28 * 28).astype('float32') / 255\n",
    "X_test = X_test.reshape(10000, 28 * 28).astype('float32') / 255\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "n_classes = 10\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input as a matrix\n",
    "Our input is stored as a matrix of shape **(samples, N_parameters)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing Data to have a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = X_train[:batch_size]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Input for NN\n",
    "Let's create input for the NN and check its shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(784)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "\n",
    "input = Input(shape=(784,))\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see **Dimension(None)** as a first dimension because Keras assume that you will have a batch as an input and **None** is the way it treats currently unknown batch size.\n",
    "\n",
    "But you can create an input with a predefined batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(784)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_with_predefined_batch_size = Input(batch_shape=(None, 784))\n",
    "input_with_predefined_batch_size.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Dense layer\n",
    "Dense is an Python object which has some parameters underneath it like `activation` or `weights` and others.\n",
    "\n",
    "Let's create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_layer = Dense(units=20, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.activations.relu>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer.activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weights are currently don't exist because Keras doesn't know the size of the input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But if we apply our *intput* as an input it will immediately create weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 20)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "output = dense_layer(input) \n",
    "W, b = dense_layer.get_weights()\n",
    "print(W.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(784)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00068538, -0.04857699, -0.01828426, ...,  0.07748862,\n",
       "        -0.06513265, -0.05795071],\n",
       "       [-0.00205623, -0.00357658,  0.07572918, ...,  0.01060609,\n",
       "        -0.05427582,  0.02552512],\n",
       "       [ 0.01380771, -0.08358473,  0.00861149, ...,  0.05522162,\n",
       "         0.04254219,  0.06668249],\n",
       "       ..., \n",
       "       [ 0.0543088 ,  0.03764609, -0.05569163, ..., -0.02976143,\n",
       "        -0.02610113,  0.07869057],\n",
       "       [ 0.0007116 , -0.07004897,  0.00306445, ...,  0.05331257,\n",
       "         0.08208139, -0.002878  ],\n",
       "       [-0.05740255,  0.04877225, -0.03829492, ..., -0.05502157,\n",
       "        -0.02743964, -0.00472681]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way **W** and **b** are initialized is specified by `kernel_initializer` and `bias_initializer` parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = Dense(20, kernel_initializer='glorot_uniform')\n",
    "output = dense_layer(input)\n",
    "W, b = dense_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01439472, -0.08547954, -0.02212189, ..., -0.05895409,\n",
       "        -0.01558902, -0.01598257],\n",
       "       [ 0.00842161, -0.00561894,  0.07029867, ...,  0.04761259,\n",
       "        -0.0202677 , -0.05342303],\n",
       "       [ 0.02258281,  0.07764402, -0.07556458, ...,  0.00333908,\n",
       "        -0.01894531, -0.01562199],\n",
       "       ..., \n",
       "       [-0.01779757, -0.08238944, -0.04750065, ..., -0.05237376,\n",
       "         0.01987977,  0.04878347],\n",
       "       [-0.05955774,  0.08158387, -0.02777416, ..., -0.03329681,\n",
       "        -0.0443873 , -0.00208463],\n",
       "       [ 0.01618721, -0.05800885, -0.00615563, ..., -0.01020557,\n",
       "        -0.05010811,  0.04970358]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model\n",
    "In Keras, to train a Neural Network we need create a model using inputs of NN and its outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(784,))\n",
    "\n",
    "# creating the dense layer object\n",
    "dense_layer = Dense(10, kernel_initializer='zeros', activation='softmax')\n",
    "\n",
    "# applying dense layer to input\n",
    "output = dense_layer(input)\n",
    "\n",
    "model = Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model main methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use even untrained NN to predict something, which will be mostly random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediction = model.predict(X_train)\n",
    "y_prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how accurate that was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy', 0.098716666666666661)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Accuracy', np.mean(np.equal(np.argmax(y_prediction, axis=-1), np.argmax(y_train, axis=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the model more thoroughly we need to compile it with **model.compile()**\n",
    "\n",
    "<img src=\"modelcompile.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can actually compute accuracy right away using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 6us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3025989532470703, 0.098716666301091507]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train, batch_size=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "We can train our model using **model.fit** function\n",
    "\n",
    "<img src=\"modelfit.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/4\n",
      "54000/54000 [==============================] - 5s 84us/step - loss: 0.4264 - categorical_accuracy: 0.8902 - val_loss: 0.2514 - val_categorical_accuracy: 0.9317\n",
      "Epoch 2/4\n",
      "54000/54000 [==============================] - 4s 79us/step - loss: 0.3000 - categorical_accuracy: 0.9165 - val_loss: 0.2366 - val_categorical_accuracy: 0.9345\n",
      "Epoch 3/4\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.2830 - categorical_accuracy: 0.9206 - val_loss: 0.2288 - val_categorical_accuracy: 0.9380\n",
      "Epoch 4/4\n",
      "54000/54000 [==============================] - 4s 77us/step - loss: 0.2742 - categorical_accuracy: 0.9233 - val_loss: 0.2271 - val_categorical_accuracy: 0.9393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f268666d8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, batch_size=16, epochs=4, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Neural Network via Matrix Operations\n",
    "\n",
    "Let's make a batch of data and pass it to network using only straight matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting new batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Slicing training data to obtain our batch\n",
    "X_batch = X_train[:batch_size]\n",
    "y_batch = y_train[:batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shapes. It should have `batch_size` number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 784)\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_batch.shape)\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to obtain weights from our trained NN from Keras as matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W, b = dense_layer.get_weights()  # obtaining W (weights) and b (biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the shapes of the parameters\n",
    "It should be consistent with number of inputs (784) and outputs (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(W.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute output of our Dense layer using pure matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = X_batch @ W + b  # sign '@' stands for matrix-matrix (and matrix-vector) multiplications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shape of the output, it should be consistent with the batch size and the number of outputs from the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to apply `softmax` function to our output. Luckily, we don't have it in NumPy library so we need to write it ourselves.\n",
    "\n",
    "Let's recap how it looks like:\n",
    "\n",
    "$$\\sigma(x)_i=\\frac{e^{x_i}}{\\sum_{k=1}^n e^{x_k}}$$\n",
    "\n",
    "In NumPy we have $e^x$ function. We can compute it directly for matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "numetrator = np.exp(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute denomenator which is a sum. Please note that we need to sum per our rows in `output`. For that we are going to use `axis` parameter which specifies according to what dimension ot sum up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denominator = np.sum(np.exp(output), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to devide numerator by denominator directly we need to reshape it to matrix instead of vector to be able to use broadcasting. This is just a feature from NumPy, so you don't need to worry about that now, but if you are curious check it out [here](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = np.expand_dims(denominator, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final computation of softmax function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_output = numetrator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the outputs from the first item in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.01630246e-04,   5.39006294e-07,   1.08486309e-03,\n",
       "         2.01682478e-01,   4.75699977e-07,   7.95593858e-01,\n",
       "         9.43825569e-07,   4.44057310e-04,   5.38417837e-04,\n",
       "         1.52730106e-04], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check whether it is looks like the output from the keras directly (**you can see that they are identical**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.01629838e-04,   5.39007431e-07,   1.08486309e-03,\n",
       "         2.01682359e-01,   4.75699608e-07,   7.95594037e-01,\n",
       "         9.43826592e-07,   4.44057194e-04,   5.38417429e-04,\n",
       "         1.52730077e-04], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_output = model.predict(X_batch)\n",
    "keras_output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain actual prediction labels we need to compute index of the max value of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_predictions = np.argmax(nn_output, axis=1)\n",
    "batch_predictions = np.argmax(y_batch, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check accuracy on this batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Manual NN Accuracy', 0.96875)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Manual NN Accuracy', np.mean(nn_predictions == batch_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is consistent with keras evaluation accuracy on this batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Keras Accuracy', 0.96875)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Keras Accuracy', model.evaluate(X_batch, y_batch)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
